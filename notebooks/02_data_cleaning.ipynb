{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6739de-79e1-4142-abab-600550bbea4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nObjective:\\nClean and preprocess raw data (Twitter, Reddit, News, and Stock Prices) to:\\n- Remove noise (URLs, mentions, emojis, symbols)\\n- Lowercase, normalize text\\n- Filter by language (English)\\n- Unify timestamps and structures\\n- Save cleaned outputs in /data/processed/\\n\\nInput: ../data/raw/\\nOutput: ../data/processed/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VesterAI - Notebook 02: Data Cleaning & Preprocessing\n",
    "\n",
    "\"\"\"\n",
    "Objective:\n",
    "Clean and preprocess raw data (Twitter, Reddit, News, and Stock Prices) to:\n",
    "- Remove noise (URLs, mentions, emojis, symbols)\n",
    "- Lowercase, normalize text\n",
    "- Filter by language (English)\n",
    "- Unify timestamps and structures\n",
    "- Save cleaned outputs in /data/processed/\n",
    "\n",
    "Input: ../data/raw/\n",
    "Output: ../data/processed/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f09b93-951a-4fc9-b659-fa716ab2e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in /home/tandel.r/.local/lib/python3.8/site-packages (2.14.1)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.7.0 in /home/tandel.r/.local/lib/python3.8/site-packages (from emoji) (4.12.2)\n",
      "Requirement already satisfied: six in /shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages (from langdetect) (1.15.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=f1e33927a624ba6c7198fc4f0214a78d43f99076c531849c48aeb5b179d1e346\n",
      "  Stored in directory: /home/tandel.r/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji langdetect\n",
    "!pip install -U jupyterlab ipywidgets jupyterlab-widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eeb87e0-89d8-4e38-91c5-835f19a4199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data will be saved in: ../data/processed/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "from langdetect import detect\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "raw_path = \"../data/raw/\"\n",
    "processed_path = \"../data/processed/\"\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "print(f\"Cleaned data will be saved in: {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35f7091-e424-44a7-bb69-994693a0d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded:\n",
      "Stock data: (1314, 6)\n",
      "News data: (20, 4)\n",
      "Twitter data: (100, 6)\n",
      "Reddit data: (50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load all available raw data\n",
    "stock_df = pd.read_csv(os.path.join(raw_path, \"AAPL_stock_data.csv\"))\n",
    "news_df = pd.read_csv(os.path.join(raw_path, \"AAPL_google_news.csv\"))\n",
    "tweet_df = pd.read_csv(os.path.join(raw_path, \"AAPL_twitter_api.csv\"))\n",
    "reddit_path = os.path.join(raw_path, \"AAPL_reddit_posts.csv\")\n",
    "reddit_df = pd.read_csv(reddit_path) if os.path.exists(reddit_path) else pd.DataFrame()\n",
    "\n",
    "print(\"Data Loaded:\")\n",
    "print(f\"Stock data: {stock_df.shape}\")\n",
    "print(f\"News data: {news_df.shape}\")\n",
    "print(f\"Twitter data: {tweet_df.shape}\")\n",
    "print(f\"Reddit data: {reddit_df.shape if not reddit_df.empty else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b44b6be-374c-4ab0-b0b9-74214869d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isnull(text): return \"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace=\"\")\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7dea5b1-9b2c-4af7-8521-95c606c622d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 5396.55it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Tweets: (95, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-25 22:54:18+00:00</td>\n",
       "      <td>best stock traders group out there updates cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-25 22:53:02+00:00</td>\n",
       "      <td>rt over the long term its hard for a stock to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-25 22:51:18+00:00</td>\n",
       "      <td>best stock trade group out there free chatroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-25 22:50:18+00:00</td>\n",
       "      <td>bast stock group discord kfc solo w jagx ino b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-25 22:47:40+00:00</td>\n",
       "      <td>bast stock group discord mac byfc tsla spy box...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                                         clean_text\n",
       "0 2025-03-25 22:54:18+00:00  best stock traders group out there updates cha...\n",
       "1 2025-03-25 22:53:02+00:00  rt over the long term its hard for a stock to ...\n",
       "2 2025-03-25 22:51:18+00:00  best stock trade group out there free chatroom...\n",
       "3 2025-03-25 22:50:18+00:00  bast stock group discord kfc solo w jagx ino b...\n",
       "4 2025-03-25 22:47:40+00:00  bast stock group discord mac byfc tsla spy box..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# Clean tweets\n",
    "tweet_df[\"clean_text\"] = tweet_df[\"text\"].progress_apply(clean_text)\n",
    "tweet_df[\"date\"] = pd.to_datetime(tweet_df[\"date\"])\n",
    "tweet_df.dropna(subset=[\"clean_text\"], inplace=True)\n",
    "\n",
    "# Optional: Remove non-English tweets\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tweet_df = tweet_df[tweet_df[\"clean_text\"].progress_apply(is_english)]\n",
    "\n",
    "print(f\"Cleaned Tweets: {tweet_df.shape}\")\n",
    "tweet_df[[\"date\", \"clean_text\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "680b9651-c803-42e4-858e-528a50703385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 9675.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned News: (20, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>clean_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>nasdaqmoreaapl quantitative stock analysis9 ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>tipranksmoreapple aapl stock shoots higher on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>seeking alphamoreapple buy now before the ipho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>yahoo financemoreapple inc aapl among the 10 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>markets insidermoredon’t expect an ai upgrade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                     clean_headline\n",
       "0 2025-03-25  nasdaqmoreaapl quantitative stock analysis9 ho...\n",
       "1 2025-03-25  tipranksmoreapple aapl stock shoots higher on ...\n",
       "2 2025-03-25  seeking alphamoreapple buy now before the ipho...\n",
       "3 2025-03-25  yahoo financemoreapple inc aapl among the 10 g...\n",
       "4 2025-03-25  markets insidermoredon’t expect an ai upgrade ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df[\"clean_headline\"] = news_df[\"headline\"].progress_apply(clean_text)\n",
    "news_df[\"date\"] = pd.to_datetime(news_df[\"date\"])\n",
    "news_df.dropna(subset=[\"clean_headline\"], inplace=True)\n",
    "\n",
    "print(f\"Cleaned News: {news_df.shape}\")\n",
    "news_df[[\"date\", \"clean_headline\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93762cca-5c1b-4ddd-aea6-febe1af9fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 573.85it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 155.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Reddit: (50, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not reddit_df.empty:\n",
    "    reddit_df[\"full_text\"] = reddit_df[\"title\"].fillna(\"\") + \" \" + reddit_df[\"content\"].fillna(\"\")\n",
    "    reddit_df[\"clean_text\"] = reddit_df[\"full_text\"].progress_apply(clean_text)\n",
    "    reddit_df[\"date\"] = pd.to_datetime(reddit_df[\"date\"])\n",
    "    reddit_df = reddit_df[reddit_df[\"clean_text\"].progress_apply(is_english)]\n",
    "    \n",
    "    print(f\"Cleaned Reddit: {reddit_df.shape}\")\n",
    "    reddit_df[[\"date\", \"clean_text\"]].head()\n",
    "else:\n",
    "    print(\"Reddit data not available, skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18307974-aff7-4f92-a596-86c7edc15a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock price data cleaned: (1313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>72.71607208251953</td>\n",
       "      <td>72.77659819422657</td>\n",
       "      <td>71.46681225027338</td>\n",
       "      <td>71.72101896406637</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>72.00912475585938</td>\n",
       "      <td>72.7717522953066</td>\n",
       "      <td>71.78396939069293</td>\n",
       "      <td>71.94133580542943</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>72.5829086303711</td>\n",
       "      <td>72.62164622763687</td>\n",
       "      <td>70.87607527260708</td>\n",
       "      <td>71.12786596061405</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>72.2415542602539</td>\n",
       "      <td>72.84923143823697</td>\n",
       "      <td>72.02123831231323</td>\n",
       "      <td>72.59260129853506</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>73.40364837646484</td>\n",
       "      <td>73.70627893727402</td>\n",
       "      <td>71.943758846659</td>\n",
       "      <td>71.943758846659</td>\n",
       "      <td>132079200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date              Close               High                Low  \\\n",
       "1 2020-01-02  72.71607208251953  72.77659819422657  71.46681225027338   \n",
       "2 2020-01-03  72.00912475585938   72.7717522953066  71.78396939069293   \n",
       "3 2020-01-06   72.5829086303711  72.62164622763687  70.87607527260708   \n",
       "4 2020-01-07   72.2415542602539  72.84923143823697  72.02123831231323   \n",
       "5 2020-01-08  73.40364837646484  73.70627893727402    71.943758846659   \n",
       "\n",
       "                Open     Volume  \n",
       "1  71.72101896406637  135480400  \n",
       "2  71.94133580542943  146322800  \n",
       "3  71.12786596061405  118387200  \n",
       "4  72.59260129853506  108872000  \n",
       "5    71.943758846659  132079200  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date to datetime\n",
    "stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"])\n",
    "stock_df = stock_df.dropna()\n",
    "print(f\"Stock price data cleaned: {stock_df.shape}\")\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02bcfdc-bcfa-4ec3-8119-8a6f14564956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to /data/processed/\n"
     ]
    }
   ],
   "source": [
    "tweet_df.to_csv(os.path.join(processed_path, \"AAPL_twitter_cleaned.csv\"), index=False)\n",
    "news_df.to_csv(os.path.join(processed_path, \"AAPL_news_cleaned.csv\"), index=False)\n",
    "stock_df.to_csv(os.path.join(processed_path, \"AAPL_stock_cleaned.csv\"), index=False)\n",
    "if not reddit_df.empty:\n",
    "    reddit_df.to_csv(os.path.join(processed_path, \"AAPL_reddit_cleaned.csv\"), index=False)\n",
    "\n",
    "print(\"Cleaned data saved to /data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7744a68f-74e9-4b8d-b78c-9099b53cdf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Summary:\n",
      "Tweets: (95, 7)\n",
      "News: (20, 5)\n",
      "Stock: (1313, 6)\n",
      "Reddit: (50, 8)\n",
      "\n",
      "Next: Perform sentiment analysis in `03_sentiment_analysis.ipynb`\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning Summary:\")\n",
    "print(f\"Tweets: {tweet_df.shape}\")\n",
    "print(f\"News: {news_df.shape}\")\n",
    "print(f\"Stock: {stock_df.shape}\")\n",
    "print(f\"Reddit: {reddit_df.shape if not reddit_df.empty else 'N/A'}\")\n",
    "\n",
    "print(\"\\nNext: Perform sentiment analysis in `03_sentiment_analysis.ipynb`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
