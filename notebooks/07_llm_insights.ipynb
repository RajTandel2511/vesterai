{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30aa64d7-c965-4db8-9838-a6eb9692751d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGoal:\\nConvert structured sentiment + stock data into instruction-tuning format suitable\\nfor LLM fine-tuning (LLaMA 2, Mistral, etc.).\\n\\nFormat:\\n- input: Context (structured features)\\n- instruction: Task description (e.g., Summarize today's market)\\n- output: Human-annotated or templated summary\\n\\nOutput File: /data/finetune_instructions.jsonl\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VesterAI - Notebook 07: Dataset Generation for LLM Fine-Tuning\n",
    "\n",
    "\"\"\"\n",
    "Goal:\n",
    "Convert structured sentiment + stock data into instruction-tuning format suitable\n",
    "for LLM fine-tuning (LLaMA 2, Mistral, etc.).\n",
    "\n",
    "Format:\n",
    "- input: Context (structured features)\n",
    "- instruction: Task description (e.g., Summarize today's market)\n",
    "- output: Human-annotated or templated summary\n",
    "\n",
    "Output File: /data/finetune_instructions.jsonl\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baff5968-16fb-4ceb-905a-b55dd8456aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(\"../data/processed/AAPL_model_data.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# Drop NA rows just in case\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c13568-28af-41a1-873e-ed4eeaba188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_record(row):\n",
    "    # Context: structured data\n",
    "    context = f\"\"\"Date: {row['Date'].strftime('%Y-%m-%d')}\n",
    "Stock Close: {row['Close']:.2f}\n",
    "Return: {row['return']:.4f}\n",
    "Twitter Sentiment: {row['twitter_sentiment']:.2f}\n",
    "News Sentiment: {row['news_sentiment']:.2f}\n",
    "Reddit Sentiment: {row.get('reddit_sentiment', 0):.2f}\n",
    "RSI: {row['rsi_14']:.2f}\n",
    "MACD: {row['macd']:.4f}\n",
    "OBV: {row['obv']:.2f}\"\"\"\n",
    "\n",
    "    instruction = \"Summarize today's market sentiment and give an investor outlook.\"\n",
    "\n",
    "    # Basic templated output for now (you can replace with GPT-generated later)\n",
    "    sentiment = \"bullish\" if row[\"twitter_sentiment\"] + row[\"news_sentiment\"] > 0 else \"bearish\"\n",
    "    rsi_status = \"overbought\" if row[\"rsi_14\"] > 70 else \"oversold\" if row[\"rsi_14\"] < 30 else \"neutral\"\n",
    "    trend = \"positive\" if row[\"return\"] > 0 else \"negative\"\n",
    "\n",
    "    output = (\n",
    "        f\"Market sentiment on {row['Date'].strftime('%Y-%m-%d')} is {sentiment}. \"\n",
    "        f\"Technical indicators like RSI are {rsi_status}. \"\n",
    "        f\"The return was {trend}, suggesting {'a potential upward move' if trend == 'positive' else 'a cautious stance'}.\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input\": context,\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e54264-ab5b-497a-94ef-40c22e2845a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning dataset saved to: ../data/finetune_instructions.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "output_path = \"../data/finetune_instructions.jsonl\"\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        record = generate_instruction_record(row)\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Fine-tuning dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5926bf64-ea67-4be6-ac9c-8344a4232bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Date: 2020-02-25\\nStock Close: 69.91\\nReturn: -0.0339\\nTwitter Sentiment: 0.00\\nNews Sentiment: 0.00\\nReddit Sentiment: 0.00\\nRSI: 30.77\\nMACD: -0.3722\\nOBV: -82898400.00', 'instruction': \"Summarize today's market sentiment and give an investor outlook.\", 'output': 'Market sentiment on 2020-02-25 is bearish. Technical indicators like RSI are neutral. The return was negative, suggesting a cautious stance.'}\n",
      "{'input': 'Date: 2020-02-26\\nStock Close: 71.02\\nReturn: 0.0159\\nTwitter Sentiment: 0.00\\nNews Sentiment: 0.00\\nReddit Sentiment: 0.00\\nRSI: 35.23\\nMACD: -0.7218\\nOBV: 115156400.00', 'instruction': \"Summarize today's market sentiment and give an investor outlook.\", 'output': 'Market sentiment on 2020-02-26 is bearish. Technical indicators like RSI are neutral. The return was positive, suggesting a potential upward move.'}\n",
      "{'input': 'Date: 2020-02-27\\nStock Close: 66.38\\nReturn: -0.0654\\nTwitter Sentiment: 0.00\\nNews Sentiment: 0.00\\nReddit Sentiment: 0.00\\nRSI: 27.30\\nMACD: -1.3578\\nOBV: -205449200.00', 'instruction': \"Summarize today's market sentiment and give an investor outlook.\", 'output': 'Market sentiment on 2020-02-27 is bearish. Technical indicators like RSI are oversold. The return was negative, suggesting a cautious stance.'}\n"
     ]
    }
   ],
   "source": [
    "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3: break\n",
    "        print(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122ed1b7-135b-47ec-a11a-cec02a4b78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook fine-tunes a LLaMA 2 model using your custom instruction dataset:\\n- Format: Instruction, Input, Output\\n- Method: PEFT with LoRA for memory-efficient tuning\\n- Target: Finetune LLaMA 2 (7B or smaller) to generate better financial summaries\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VesterAI - Notebook 07: Fine-Tuning LLM (LLaMA 2) on Financial Sentiment\n",
    "\n",
    "\"\"\"\n",
    "This notebook fine-tunes a LLaMA 2 model using your custom instruction dataset:\n",
    "- Format: Instruction, Input, Output\n",
    "- Method: PEFT with LoRA for memory-efficient tuning\n",
    "- Target: Finetune LLaMA 2 (7B or smaller) to generate better financial summaries\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05b80ab-09d1-4819-af9c-ae3f23dea1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db453b9c-5f4a-47ec-a22a-67c092c4d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b159490ae45416b8987396882094988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Date: 2020-02-25\\nStock Close: 69.91\\nReturn: -0.0339\\nTwitter Sentiment: 0.00\\nNews Sentiment: 0.00\\nReddit Sentiment: 0.00\\nRSI: 30.77\\nMACD: -0.3722\\nOBV: -82898400.00',\n",
       " 'instruction': \"Summarize today's market sentiment and give an investor outlook.\",\n",
       " 'output': 'Market sentiment on 2020-02-25 is bearish. Technical indicators like RSI are neutral. The return was negative, suggesting a cautious stance.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from JSONL file\n",
    "dataset = load_dataset(\"json\", data_files=\"../data/finetune_instructions.jsonl\", split=\"train\")\n",
    "\n",
    "# Preview\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d9b383-fe32-4762-8c6b-561766fab214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tandel.r/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9041b457ae4718a7fe96a17b694f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tandel.r/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # Or use your local path if already downloaded\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Fix: Assign pad_token if it's missing (common in LLaMA/Mistral)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load model with 4-bit quantization and auto GPU mapping\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188991a9-fc12-4aea-98a5-13a95aa6b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea701614d394f0e81c719d2089d7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_instruction(example):\n",
    "    return {\n",
    "        \"text\": f\"\"\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\"\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36187c1-1f80-4a18-93ad-9ce9cc533c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23f7b739aa943aaa9a0d6d2375f19dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"text\", \"instruction\", \"input\", \"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d0d8d7-65ce-41fd-9835-c2bdafca758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 3,504,607,232 || trainable%: 0.11967971650867153\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe31bd99-ff6f-408a-a9ed-f675e287e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2400/2400 1:30:48, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.289400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2400, training_loss=0.307043784459432, metrics={'train_runtime': 5450.8309, 'train_samples_per_second': 7.028, 'train_steps_per_second': 0.44, 'total_flos': 3.9702569391489024e+17, 'train_loss': 0.307043784459432, 'epoch': 30.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/llama2_finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244a118a-78d9-4973-90f3-4af537b831ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/llama2_finetuned\")\n",
    "tokenizer.save_pretrained(\"../models/llama2_finetuned\")\n",
    "print(\"Fine-tuned model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "916b6186-87d5-4fcb-890e-ead6dc94ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Summarize today's market sentiment and give an investor outlook.\n",
      "\n",
      "### Input:\n",
      "Date: 2025-03-20\n",
      "Stock Close: 182.12\n",
      "Return: 0.0032\n",
      "Twitter Sentiment: 0.42\n",
      "News Sentiment: 0.36\n",
      "Reddit Sentiment: 0.11\n",
      "RSI: 58.32\n",
      "MACD: 0.0012\n",
      "OBV: 512321000\n",
      "\n",
      "### Response:\n",
      "Stock Close: 182.12\n",
      "Return: 0.0032\n",
      "Twitter Sentiment: 0.00\n",
      "News Sentiment: 0.00\n",
      "Reddit Sentiment: 0.00\n",
      "Sentiment: 0.42\n",
      "TE Technical Signal: 0.00\n",
      "TW Technical Signal: 0.00\n",
      "SUM Technical Signal: 0.00\n",
      "RSI: 58.32\n",
      "MACD: 0.0012\n",
      "OBV: 512321000\n",
      "RSI Stoch Change: 0.00\n",
      "OBOR Sto\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"\"\"### Instruction:\n",
    "Summarize today's market sentiment and give an investor outlook.\n",
    "\n",
    "### Input:\n",
    "Date: 2025-03-20\n",
    "Stock Close: 182.12\n",
    "Return: 0.0032\n",
    "Twitter Sentiment: 0.42\n",
    "News Sentiment: 0.36\n",
    "Reddit Sentiment: 0.11\n",
    "RSI: 58.32\n",
    "MACD: 0.0012\n",
    "OBV: 512321000\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "out = pipe(prompt, max_new_tokens=150)[0][\"generated_text\"]\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
